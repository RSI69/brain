# ðŸ§  multi-llm

Local, private, multi-model AI chat engine with brutal honesty and real safety filters.  
**Runs 100% offline.**

---

## Features

- Multiple local LLMs (route code, chat, long-context)
- No flattery, no apologies â€” brutal, profanity-enabled replies (edit backend to change)
- Remembers last 5 messages per session
- Built-in safety filters (blocks credit cards, CP, bomb guides, scams)
- Streaming replies with % progress bar
- FastAPI backend + simple local web UI
- Open source, MIT license

---

## Requirements

- **GPU:** NVIDIA 3080+ or Apple M-series  
- **RAM:** 16GB minimum  
- **OS:** Windows (tested) or Linux  
- **Python:** 3.10

---

## ðŸš€ Quick Setup (Windows, 5 Minutes)

### 1. Install Python 3.10

- [Download Python 3.10](https://www.python.org/downloads/release/python-3100/)
- **IMPORTANT:** Check "Add Python to PATH" during install

---

### 2. Download and Unzip

Unzip the `multi-llm` folder anywhere (e.g., `C:\AI\multi-llm`)

---

### 3. Open Command Prompt in the Folder

```cmd
cd C:\AI\multi-llm
